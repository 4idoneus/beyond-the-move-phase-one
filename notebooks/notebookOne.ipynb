{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30381987",
   "metadata": {},
   "source": [
    "## 1. The Challenge\n",
    "\n",
    "I needed to process 20,000 Professional Go games (SGF format) into a numerical format (Tensors) that my Neural Network could read.\n",
    "\n",
    "Each game consists of approximately 200 moves. My initial goal was to save every board state as a training example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a3d806",
   "metadata": {},
   "source": [
    "## 2. The Initial Approach (The Mistake)\n",
    "\n",
    "My first script (`process.py`) was designed to iterate through every move of every game and save it immediately as a separate .npz file.\n",
    "\n",
    "### ðŸ”´ The \"Bad\" Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1efa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pseudo-code of the initial failure\n",
    "# for game in 20_000_games:\n",
    "#     for move in game.moves: # Approx 200 moves per game\n",
    "#         # 1. Encode board to 19x19x17 tensor\n",
    "#         tensor = encoder.encode(board)\n",
    "#         \n",
    "#         # 2. Save IMMEDIATELY to disk\n",
    "#         # Problem: This runs 200 times per game\n",
    "#         np.save(f\"data/processed/game_{id}_move_{move_num}.npz\", tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1a6713",
   "metadata": {},
   "source": [
    "## 3. The Bottleneck Analysis\n",
    "\n",
    "When I ran this script, my computer froze, and the processing speed dropped drastically.\n",
    "\n",
    "### The Math\n",
    "\n",
    "$$20,000 \\text{ games} \\times 200 \\text{ moves/game} = 4,000,000 \\text{ files}$$\n",
    "\n",
    "### Why this failed:\n",
    "\n",
    "1. **Inode Exhaustion**: File systems (like NTFS or ext4) struggle to index millions of tiny files in a single folder.\n",
    "\n",
    "2. **I/O Latency**: The time spent opening and closing 4 million files was greater than the time spent actually processing the data.\n",
    "\n",
    "3. **Manageability**: Moving, deleting, or loading 4 million files later would be impossible for the OS explorer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e72a99",
   "metadata": {},
   "source": [
    "## 4. The Solution: Batching\n",
    "\n",
    "I refactored the pipeline to aggregate all moves from a single game into a list in memory, and then save one file per game.\n",
    "\n",
    "### ðŸŸ¢ The Optimized Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41ead4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pseudo-code of the fix\n",
    "# for game in 20_000_games:\n",
    "#     # Create temporary lists in RAM\n",
    "#     game_inputs = []\n",
    "#     game_targets = []\n",
    "#\n",
    "#     for move in game.moves:\n",
    "#         tensor = encoder.encode(board)\n",
    "#         game_inputs.append(tensor) # Store in RAM\n",
    "#         game_targets.append(move_coord)\n",
    "#\n",
    "#     # Save ONCE per game\n",
    "#     # Reduces file count by factor of ~200\n",
    "#     save_path = f\"data/processed/game_{id}.npz\"\n",
    "#     np.savez_compressed(save_path, inputs=game_inputs, targets=game_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57c7355",
   "metadata": {},
   "source": [
    "## 5. Results\n",
    "\n",
    "| Metric | Before | After | Improvement |\n",
    "|--------|--------|-------|-------------|\n",
    "| **Total Files** | 4,000,000 | 20,000 | 200x reduction |\n",
    "| **Disk Usage** | Highly fragmented | Efficient (compressed) | âœ“ |\n",
    "| **Loading Speed** | Extremely slow | Fast (200 examples per file) | âœ“ |\n",
    "\n",
    "### Key Improvements\n",
    "\n",
    "$$\\text{File Reduction} = \\frac{4,000,000}{20,000} = 200\\times$$\n",
    "\n",
    "- **Disk Usage**: Efficient (due to `np.savez_compressed`).\n",
    "- **Loading Speed**: PyTorch Dataset can now open one file and get 200 examples instantly, drastically speeding up training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20458356",
   "metadata": {},
   "source": [
    "## Key Takeaway\n",
    "\n",
    "**Always calculate total file output before running a massive loop.** I/O overhead is often the silent killer in ML pipelines.\n",
    "\n",
    "### Lessons Learned\n",
    "\n",
    "- âœ“ Batch operations in memory before writing to disk\n",
    "- âœ“ Estimate file system impact (inode limits, I/O bottlenecks)\n",
    "- âœ“ Use compression when saving large arrays\n",
    "- âœ“ Profile your code to identify bottlenecks early"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5822880",
   "metadata": {},
   "source": [
    "The fist process.py caused the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef1535e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from sgfmill import sgf, boards\n",
    "from encoder import GoBoardEncoder\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "RAW_DATA_DIR = 'data/raw'\n",
    "PROCESSED_DIR = 'data/processed'\n",
    "MAX_GAMES_TO_PROCESS = 20000  # Limit for testing\n",
    "\n",
    "if not os.path.exists(PROCESSED_DIR):\n",
    "    os.makedirs(PROCESSED_DIR)\n",
    "\n",
    "class GameStateWrapper:\n",
    "    def __init__(self, sgfmill_board, color_to_move):\n",
    "        self.board_size = 19\n",
    "        self.board = np.zeros((19, 19), dtype=int)\n",
    "        self.color_to_move = color_to_move\n",
    "        for r in range(19):\n",
    "            for c in range(19):\n",
    "                color = sgfmill_board.get(r, c)\n",
    "                if color == 'b': self.board[r][c] = 1\n",
    "                elif color == 'w': self.board[r][c] = 2\n",
    "\n",
    "def get_sgf_content(filepath):\n",
    "    with open(filepath, 'rb') as f:\n",
    "        raw_data = f.read()\n",
    "    try:\n",
    "        return raw_data.decode('utf-8')\n",
    "    except UnicodeDecodeError:\n",
    "        try:\n",
    "            return raw_data.decode('gb18030')\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "def process_games():\n",
    "    encoder = GoBoardEncoder()\n",
    "    # Case insensitive search for .sgf, .SGF, etc.\n",
    "    files = glob.glob(os.path.join(RAW_DATA_DIR, '*.[sS][gG][fF]'))\n",
    "    \n",
    "    print(f\"ðŸ“‚ Found {len(files)} SGF files. Processing up to {MAX_GAMES_TO_PROCESS}...\")\n",
    "    \n",
    "    processed_count = 0\n",
    "    \n",
    "    for i, filepath in enumerate(files):\n",
    "        if processed_count >= MAX_GAMES_TO_PROCESS:\n",
    "            break\n",
    "\n",
    "        sgf_content = get_sgf_content(filepath)\n",
    "        if sgf_content is None: continue\n",
    "\n",
    "        try:\n",
    "            game = sgf.Sgf_game.from_string(sgf_content)\n",
    "            \n",
    "            # --- DATA DIET FILTER ---\n",
    "            # Only keep games where players are  9d, or Pro (p)\n",
    "            # This ensures r AI learns from \"Pro / Andvanced Amatures\", not amateurs.\n",
    "            root = game.get_root()\n",
    "            try:\n",
    "                b_rank = root.get(\"BR\").lower()\n",
    "                w_rank = root.get(\"WR\").lower()\n",
    "                # Simple check: if 'd' is in rank, check digit. If 'p' is in rank, keep it.\n",
    "                is_high_dan = ('p' in b_rank) or ('p' in w_rank) or \\\n",
    "                              ('9d' in b_rank) or ('9d' in w_rank)\n",
    "                if not is_high_dan:\n",
    "                    continue \n",
    "            except:\n",
    "                # If rank is missing, skip or keep depending on preference\n",
    "                continue \n",
    "\n",
    "            board = boards.Board(19)\n",
    "            filename_base = os.path.basename(filepath).replace('.sgf', '')\n",
    "            \n",
    "            # Arrays to hold ALL moves for this single game\n",
    "            game_inputs = []\n",
    "            game_targets = []\n",
    "            \n",
    "            for move_node in game.get_main_sequence():\n",
    "                color, move_coords = move_node.get_move()\n",
    "                if move_coords is None: continue \n",
    "                \n",
    "                row, col = move_coords\n",
    "                \n",
    "                # 1. Encode\n",
    "                game_state = GameStateWrapper(board, color)\n",
    "                input_tensor = encoder.encode(game_state)\n",
    "                target_index = row * 19 + col\n",
    "                \n",
    "                # 2. Collect (Don't save yet)\n",
    "                game_inputs.append(input_tensor)\n",
    "                game_targets.append(target_index)\n",
    "                \n",
    "                # 3. Update\n",
    "                board.play(row, col, color)\n",
    "            \n",
    "            # 4. SAVE ONCE PER GAME\n",
    "            if len(game_inputs) > 0:\n",
    "                save_path = os.path.join(PROCESSED_DIR, f\"{filename_base}.npz\")\n",
    "                \n",
    "                # Stack them: Inputs becomes (N, 17, 19, 19), Targets becomes (N,)\n",
    "                np.savez_compressed(\n",
    "                    save_path, \n",
    "                    inputs=np.array(game_inputs, dtype=np.float32), \n",
    "                    targets=np.array(game_targets, dtype=np.int64)\n",
    "                )\n",
    "                processed_count += 1\n",
    "                if processed_count % 100 == 0:\n",
    "                    print(f\"âœ… Processed {processed_count} games...\")\n",
    "\n",
    "        except Exception as e:\n",
    "            # Don't crash on one bad file\n",
    "            continue\n",
    "\n",
    "    print(f\"ðŸŽ‰ DONE! Processed {processed_count} valid high-quality games.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_games()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
